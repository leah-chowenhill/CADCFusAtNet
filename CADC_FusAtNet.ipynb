{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/leah-chowenhill/CADCFusAtNet/blob/main/CADC_FusAtNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "noZ6WLdGyK1p"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/ShivamP1993/FusAtNet-Dual-Attention-based-SpectroSpatial-Multimodal-Fusion-Network-for-Hyperspectral-and-LiDAR-.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_gJ0YZTAykRZ"
      },
      "outputs": [],
      "source": [
        "#!unzip '/content/drive/MyDrive/Perception_in_Snow/data.zip'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!mkdir '/content/drive/MyDrive/Perception_in_Snow/CADCFusAtNet'\n",
        "#!cp -r '/content/FusAtNet-Dual-Attention-based-SpectroSpatial-Multimodal-Fusion-Network-for-Hyperspectral-and-LiDAR-' '/content/drive/MyDrive/Perception_in_Snow/CADCFusAtNet'"
      ],
      "metadata": {
        "id": "_NpPhNlzgJv9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fub7E_dGyWz9",
        "outputId": "4baf8f73-118c-4620-dd14-8796f866e15c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call data loader\n",
        "!python3 /content/drive/MyDrive/Perception_in_Snow/CADCFusAtNet/FusAtNet-Dual-Attention-based-SpectroSpatial-Multimodal-Fusion-Network-for-Hyperspectral-and-LiDAR-/data_load.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gq5Ycp-ypkca",
        "outputId": "eff5f043-2149-47fb-e804-3551c0429fdd"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 3/3 [00:10<00:00,  3.53s/it]\n",
            "feat norm save done!\n",
            "groundtruth save done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "DpQlskklyo0P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2eeee39-2683-4a22-af04-56ac50dcf8a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test patch iteration:\n",
            "0\n",
            "patches function called\n",
            "100% 1/1 [01:20<00:00, 80.90s/it]\n",
            "Index Done!\n",
            "1\n",
            "patches function called\n",
            "100% 1/1 [00:18<00:00, 18.90s/it]\n",
            "Index Done!\n",
            "2\n",
            "patches function called\n",
            "100% 1/1 [00:17<00:00, 17.45s/it]\n",
            "Index Done!\n",
            "3\n",
            "patches function called\n",
            "100% 1/1 [00:22<00:00, 22.20s/it]\n",
            "Index Done!\n",
            "4\n",
            "patches function called\n",
            "100% 1/1 [00:26<00:00, 26.03s/it]\n",
            "Index Done!\n",
            "5\n",
            "patches function called\n",
            "100% 1/1 [00:12<00:00, 12.02s/it]\n",
            "Index Done!\n",
            "6\n",
            "patches function called\n",
            "100% 1/1 [00:17<00:00, 17.13s/it]\n",
            "Index Done!\n",
            "7\n",
            "patches function called\n",
            "100% 1/1 [00:41<00:00, 41.71s/it]\n",
            "Index Done!\n",
            "8\n",
            "patches function called\n",
            "100% 1/1 [00:13<00:00, 13.74s/it]\n",
            "Index Done!\n",
            "9\n",
            "patches function called\n",
            "100% 1/1 [00:37<00:00, 37.73s/it]\n",
            "Index Done!\n",
            "10\n",
            "patches function called\n",
            "100% 1/1 [00:21<00:00, 21.72s/it]\n",
            "Index Done!\n",
            "11\n",
            "patches function called\n",
            "100% 1/1 [00:17<00:00, 17.78s/it]\n",
            "Index Done!\n",
            "12\n",
            "patches function called\n",
            "100% 1/1 [00:33<00:00, 33.25s/it]\n",
            "Index Done!\n",
            "13\n",
            "patches function called\n",
            "100% 1/1 [00:29<00:00, 29.46s/it]\n",
            "Index Done!\n",
            "14\n",
            "patches function called\n",
            "100% 1/1 [00:23<00:00, 23.02s/it]\n",
            "Index Done!\n",
            "15\n",
            "patches function called\n",
            "100% 1/1 [00:13<00:00, 13.79s/it]\n",
            "Index Done!\n",
            "16\n",
            "patches function called\n",
            "100% 1/1 [00:30<00:00, 30.90s/it]\n",
            "Index Done!\n",
            "17\n",
            "patches function called\n",
            "100% 1/1 [00:23<00:00, 23.14s/it]\n",
            "Index Done!\n",
            "18\n",
            "patches function called\n",
            "100% 1/1 [00:13<00:00, 13.89s/it]\n",
            "Index Done!\n",
            "19\n",
            "patches function called\n",
            "100% 1/1 [00:30<00:00, 30.73s/it]\n",
            "Index Done!\n",
            "20\n",
            "patches function called\n",
            "100% 1/1 [00:23<00:00, 23.80s/it]\n",
            "Index Done!\n",
            "21\n",
            "patches function called\n",
            "100% 1/1 [00:22<00:00, 22.64s/it]\n",
            "Index Done!\n",
            "22\n",
            "patches function called\n",
            "100% 1/1 [00:37<00:00, 37.05s/it]\n",
            "Index Done!\n",
            "23\n",
            "patches function called\n",
            "100% 1/1 [00:22<00:00, 22.37s/it]\n",
            "Index Done!\n",
            "24\n",
            "patches function called\n",
            "100% 1/1 [00:17<00:00, 17.91s/it]\n",
            "Index Done!\n",
            "25\n",
            "patches function called\n",
            "100% 1/1 [00:20<00:00, 20.58s/it]\n",
            "Index Done!\n",
            "26\n",
            "patches function called\n",
            "100% 1/1 [00:24<00:00, 24.79s/it]\n",
            "Index Done!\n",
            "27\n",
            "patches function called\n",
            "100% 1/1 [00:25<00:00, 25.28s/it]\n",
            "Index Done!\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# Call patch generator\n",
        "!python3 /content/drive/MyDrive/Perception_in_Snow/CADCFusAtNet/FusAtNet-Dual-Attention-based-SpectroSpatial-Multimodal-Fusion-Network-for-Hyperspectral-and-LiDAR-/data_prepare.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "''' \n",
        "last train iter = 63\n",
        "numpy train files = 4\n",
        "\n",
        "last test iter = 27\n",
        "numpy test files = 2\n",
        "'''\n",
        "\n",
        "# Call data augmentor\n",
        "!python3 /content/drive/MyDrive/Perception_in_Snow/CADCFusAtNet/FusAtNet-Dual-Attention-based-SpectroSpatial-Multimodal-Fusion-Network-for-Hyperspectral-and-LiDAR-/data_augmentation.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBbgoZmVjsXu",
        "outputId": "e5b12adf-200b-4c73-d12d-d19a5ab97f90"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2597360, 11, 11, 3)\n",
            "(2597360,)\n",
            "Done!\n",
            "\r  0% 0/2820 [00:00<?, ?it/s]\r 78% 2207/2820 [00:00<00:00, 22059.45it/s]\r100% 2820/2820 [00:00<00:00, 21914.26it/s]\n",
            "final train labels shape: (5640,)\n",
            "final patches shape: (5640, 11, 11, 3)\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Call model instance\n",
        "!python3 /content/drive/MyDrive/Perception_in_Snow/CADCFusAtNet/FusAtNet-Dual-Attention-based-SpectroSpatial-Multimodal-Fusion-Network-for-Hyperspectral-and-LiDAR-/model.py"
      ],
      "metadata": {
        "id": "FqvIyaeG-DQX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "842df87f-2322-4852-ce5d-c4e033358e31"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-05-04 03:20:03.884422: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-04 03:20:06.999252: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/keras/layers/normalization/batch_normalization.py:581: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "myohc: (5640, 1)\n",
            "Train on 5640 samples\n",
            "2023-05-04 03:22:02.521260: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:353] MLIR V1 optimization pass is not enabled\n",
            "2023-05-04 03:22:03.846590: W tensorflow/c/c_api.cc:300] Operation '{name:'training/Nadam/convatt3/bias/v/Assign' id:5360 op device:{requested: '', assigned: ''} def:{{{node training/Nadam/convatt3/bias/v/Assign}} = AssignVariableOp[_has_manual_control_dependencies=true, dtype=DT_FLOAT, validate_shape=false](training/Nadam/convatt3/bias/v, training/Nadam/convatt3/bias/v/Initializer/zeros)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
            "5640/5640 [==============================] - 1774s 315ms/sample - loss: 90.4697 - accuracy: 0.9546\n",
            "/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py:2359: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  updates=self.state_updates,\n",
            "2023-05-04 03:51:42.237913: W tensorflow/c/c_api.cc:300] Operation '{name:'reshape/Reshape' id:2608 op device:{requested: '', assigned: ''} def:{{{node reshape/Reshape}} = Reshape[T=DT_FLOAT, Tshape=DT_INT32, _has_manual_control_dependencies=true](convcl6/Softmax, reshape/Reshape/shape)}}' was changed by setting attribute after it was run by a session. This mutation will have no effect, and will trigger an error in the future. Either don't modify nodes after running them or create a new session.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/Perception_in_Snow/CADCFusAtNet/FusAtNet-Dual-Attention-based-SpectroSpatial-Multimodal-Fusion-Network-for-Hyperspectral-and-LiDAR-/model.py\", line 437, in <module>\n",
            "    preds2 = model_att.predict([test_hsi, test_lidar], verbose = 1)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training_v1.py\", line 1059, in predict\n",
            "    return func.predict(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training_arrays_v1.py\", line 801, in predict\n",
            "    return predict_loop(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training_arrays_v1.py\", line 421, in model_iteration\n",
            "    batch_outs = f(ins_batch)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/keras/backend.py\", line 4608, in __call__\n",
            "    fetched = self._callable_fn(*array_vals, run_metadata=self.run_metadata)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/client/session.py\", line 1481, in __call__\n",
            "    ret = tf_session.TF_SessionRunCallable(self._session._session,\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize predictions\n",
        "\n",
        "!unzip '/content/drive/MyDrive/Perception_in_Snow/data.zip'\n",
        "\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()\n",
        "\n",
        "def display_mask(i):\n",
        "    \"\"\"Quick utility to display a model's prediction.\"\"\"\n",
        "    mask = np.argmax(val_preds[i], axis=-1)\n",
        "    mask = np.expand_dims(mask, axis=-1)\n",
        "    img = ImageOps.autocontrast(keras.preprocessing.image.array_to_img(mask))\n",
        "    display(img)\n",
        "\n",
        "# Display input image\n",
        "img = Image.open('/content/drive/MyDrive/Perception_in_Snow/data/cadcd/2019_02_27/0013/labeled/image_00/data/0000000095.png')\n",
        "img.show()\n",
        "\n",
        "# Display mask predicted by our model\n",
        "result = display_mask(i)\n",
        "imgplot = plt.imshow(results)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "CeT-620Z-CrV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPylm9IuaW8qkTZU0QO3tmR",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}